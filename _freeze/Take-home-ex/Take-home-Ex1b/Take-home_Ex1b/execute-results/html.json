{
  "hash": "e29f31379fa5012ecad4f2387e316c0a",
  "result": {
    "markdown": "---\ntitle: \"Take-home Exercise 4b\"\ndate: March 17, 2024\ndate-modified: \"last-modified\"\nauthor: \"Imran Ibrahim\"\ntoc: true\nexecute: \n  eval: true\n  echo: true\n  freeze: true\n  warning: false\n  message: false\n---\n\n\n# Getting Started\n\n## Loading R packages and Data prep\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, dplyr , \n               sf, lubridate,plotly,\n               tmap, spdep, sfdep)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nACLED_MMR <- read_csv(\"data/MMR.csv\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmmr_shp_mimu_2 <-  st_read(dsn = \"data/geospatial3\",  \n                  layer = \"mmr_polbnda_adm2_250k_mimu\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `mmr_polbnda_adm2_250k_mimu' from data source \n  `C:\\imranmi\\ISSS608-VAA\\Take-home-ex\\Take-home-Ex1b\\data\\geospatial3' \n  using driver `ESRI Shapefile'\nSimple feature collection with 80 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmmr_shp_mimu_1 <-  st_read(dsn = \"data/geospatial3\",  \n                  layer = \"mmr_polbnda2_adm1_250k_mimu_1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `mmr_polbnda2_adm1_250k_mimu_1' from data source \n  `C:\\imranmi\\ISSS608-VAA\\Take-home-ex\\Take-home-Ex1b\\data\\geospatial3' \n  using driver `ESRI Shapefile'\nSimple feature collection with 18 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nACLED_MMR_1 <- ACLED_MMR %>%\n  mutate(admin1 = case_when(\n    admin1 == \"Bago-East\" ~ \"Bago (East)\",\n    admin1 == \"Bago-West\" ~ \"Bago (West)\",\n    admin1 == \"Shan-North\" ~ \"Shan (North)\",\n    admin1 == \"Shan-South\" ~ \"Shan (South)\",\n    admin1 == \"Shan-East\" ~ \"Shan (East)\",\n    TRUE ~ as.character(admin1)\n  ))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nACLED_MMR_1 <- ACLED_MMR_1 %>%\n  mutate(admin2 = case_when(\n    admin2 == \"Yangon-East\" ~ \"Yangon (East)\",\n    admin2 == \"Yangon-West\" ~ \"Yangon (West)\",\n    admin2 == \"Yangon-North\" ~ \"Yangon (North)\",\n    admin2 == \"Yangon-South\" ~ \"Yangon (South)\",\n    admin2 == \"Mong Pawk (Wa SAD)\" ~ \"Tachileik\",\n    admin2 == \"Nay Pyi Taw\" ~ \"Det Khi Na\",\n    admin2 == \"Yangon\" ~ \"Yangon (West)\",\n    TRUE ~ as.character(admin2)\n  ))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nEvents2 <- ACLED_MMR_1 %>%\n    group_by(year, admin2, event_type) %>%\n    summarise(Incidents = n(),\n              Fatalities = sum(fatalities, na.rm = TRUE)) %>%\n              \n    ungroup()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nEvents_admin2 <- left_join(mmr_shp_mimu_2, Events2,\n                            by = c(\"DT\" = \"admin2\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nEvents_admin2 <- Events_admin2 %>%\n                      select(-OBJECTID, -ST, -ST_PCODE, \n                             -DT_PCODE, -DT_MMR, -PCode_V)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(Events_admin2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"sf\"         \"data.frame\"\n```\n:::\n:::\n\n\n# Filtering the Event and Year (Event type = Battles, in 2022)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBattles_2022 <- Events_admin2 %>%\n  filter(year == 2023, event_type == \"Battles\")\n```\n:::\n\n\n# Local Measures of Spatial Autocorrelation - sfdep methods\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(Battles_2022) +\n  tm_fill(\"Incidents\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Incidents\") +\n  \n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex1b_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n## Global Measures of Spatial Association\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#wm_q <- poly2nb(Battles_2022, \n                #queen=TRUE)\n#summary(wm_q)\n```\n:::\n\n\n### Deriving contiguity weights: Queen’s method\n\nIn the code chunk below, queen method is used to derive the contiguity weights.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q <- Battles_2022 %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\",\n                         allow_zero = TRUE),\n         .before = 1) \n```\n:::\n\n\nNotice that `st_weights()` provides 3 arguments, they are:\n\n-   *nb*: A neighbor list object as created by `st_neighbours().`\n\n-   *style*: Default “W” for row standardized weights. This value can also be “B”, “C”, “U”, “minmax”, and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n\n-   *allow_zero*: If TRUE, assigns zero as lagged value to zone without neighbors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSimple feature collection with 74 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 99.66532 ymax: 28.54554\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                        nb\n1          3, 7, 8, 32, 72\n2                        4\n3                    1, 32\n4                    2, 73\n5     6, 8, 20, 66, 72, 73\n6  5, 7, 8, 19, 20, 27, 67\n7          1, 6, 8, 27, 32\n8           1, 5, 6, 7, 72\n9               10, 34, 43\n10           9, 11, 23, 34\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                                            1\n3                                                                     0.5, 0.5\n4                                                                     0.5, 0.5\n5             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n6  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n7                                                      0.2, 0.2, 0.2, 0.2, 0.2\n8                                                      0.2, 0.2, 0.2, 0.2, 0.2\n9                                              0.3333333, 0.3333333, 0.3333333\n10                                                      0.25, 0.25, 0.25, 0.25\n           DT year event_type Incidents Fatalities\n1    Hinthada 2023    Battles         4          3\n2     Labutta 2023    Battles         1          1\n3     Pathein 2023    Battles         3          1\n4      Pyapon 2023    Battles         3          2\n5        Bago 2023    Battles        50        270\n6     Taungoo 2023    Battles        87        493\n7        Pyay 2023    Battles        34         59\n8  Thayarwady 2023    Battles        50         93\n9       Falam 2023    Battles        27         89\n10      Hakha 2023    Battles        48        210\n                         geometry\n1  MULTIPOLYGON (((95.12637 18...\n2  MULTIPOLYGON (((95.04462 15...\n3  MULTIPOLYGON (((94.27572 15...\n4  MULTIPOLYGON (((95.20798 15...\n5  MULTIPOLYGON (((95.90674 18...\n6  MULTIPOLYGON (((96.17964 19...\n7  MULTIPOLYGON (((95.70458 19...\n8  MULTIPOLYGON (((95.85173 18...\n9  MULTIPOLYGON (((93.36931 24...\n10 MULTIPOLYGON (((93.35213 23...\n```\n:::\n:::\n\n\n### Computing Global Moran’ I\n\nIn the code chunk below, global_moran() function is used to compute the Moran’s I value. Different from spdep package, the output is a tibble data.frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoranI <- global_moran(wm_q$Incidents,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 2\n $ I: num 0.283\n $ K: num 6.98\n```\n:::\n:::\n\n\n### Performing Global Moran’sI test\n\nIn general, Moran’s I test will be performed instead of just computing the Moran’s I statistics. With sfdep package, Moran’s I test can be performed by using [`global_moran_test()`](https://sfdep.josiahparry.com/reference/global_moran_test.html) as shown in the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_test(wm_q$Incidents,\n                       wm_q$nb,\n                       wm_q$wt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tMoran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 3.8526, p-value = 5.844e-05\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.283471480      -0.013698630       0.005949903 \n```\n:::\n:::\n\n\n### Performing Global Moran’I permutation test\n\nIn practice, monte carlo simulation should be used to perform the statistical test. For **sfdep**, it is supported by [`global_moran_perm()`](https://sfdep.josiahparry.com/reference/global_moran_perm.html)\n\nIt is alway a good practice to use `set.seed()` before performing simulation. This is to ensure that the computation is reproducible.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n```\n:::\n\n\nNext, `global_moran_perm()` is used to perform Monte Carlo simulation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_perm(wm_q$Incidents,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tMonte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.28347, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n```\n:::\n:::\n\n\nThe statistical report above show that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of Incidents for event type==Battle, resemble random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering.\n\n## Computing local Moran’s I\n\nIn this section, we learn how to compute Local Moran’s I of Incidents at admin 2 level (Districts) by using [`local_moran()`](https://sfdep.josiahparry.com/reference/local_moran.html) of sfdep package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa <- wm_q %>% \n  mutate(local_moran = local_moran(\n    Incidents, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_moran)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSimple feature collection with 74 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 99.66532 ymax: 28.54554\nGeodetic CRS:  WGS 84\n# A tibble: 74 × 20\n         ii       eii   var_ii    z_ii  p_ii p_ii_sim p_folded_sim skewness\n      <dbl>     <dbl>    <dbl>   <dbl> <dbl>    <dbl>        <dbl>    <dbl>\n 1  0.463    0.00682  0.160     1.14   0.255     0.12         0.06   -1.45 \n 2  0.713   -0.0164   0.961     0.744  0.457     0.32         0.19   -1.79 \n 3  0.692   -0.0176   0.214     1.53   0.125     0.02         0.01   -0.726\n 4  0.685   -0.00959  0.272     1.33   0.183     0.04         0.02   -1.60 \n 5  0.00628 -0.000598 0.000186  0.504  0.614     0.66         0.33   -0.904\n 6 -0.230    0.0207   0.0499   -1.12   0.262     0.22         0.11    0.451\n 7  0.105   -0.0194   0.0159    0.991  0.322     0.34         0.17   -0.564\n 8  0.00910 -0.000254 0.000178  0.701  0.484     0.52         0.26   -0.872\n 9 -0.00752 -0.00344  0.0526   -0.0178 0.986     0.8          0.4    -1.17 \n10 -0.0113   0.00545  0.000750 -0.613  0.540     0.52         0.26   -0.294\n# ℹ 64 more rows\n# ℹ 12 more variables: kurtosis <dbl>, mean <fct>, median <fct>, pysal <fct>,\n#   nb <nb>, wt <list>, DT <chr>, year <dbl>, event_type <chr>,\n#   Incidents <int>, Fatalities <dbl>, geometry <MULTIPOLYGON [°]>\n```\n:::\n:::\n\n\nThe output of `local_moran()` is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.\n\n-   ii: local moran statistic\n\n-   eii: expectation of local moran statistic; for localmoran_permthe permutation sample means\n\n-   var_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations\n\n-   z_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations\n\n-   p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations p_ii_sim: For `localmoran_perm()`, `rank()` and `punif()` of observed statistic rank for \\[0, 1\\] p-values using `alternative=` -p_folded_sim: the simulation folded \\[0, 0.5\\] range ranked p-value (based on https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b cadcbecc5e061/esda/crand.py#L211-L213)\n\n-   skewness: For `localmoran_perm`, the output of e1071::skewness() for the permutation samples underlying the standard deviates\n\n-   kurtosis: For `localmoran_perm`, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.\n\n### Visualising local Moran’s I\n\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the *ii* field.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Incidents\",\n            main.title.size = 0.8)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex1b_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n### Visualising p-value of local Moran’s I\n\nIn the code chunk below, tmap functions are used prepare a choropleth map by using value in the *p_ii_sim* field.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex1b_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n### Visuaising local Moran’s I and p-value\n\nFor effective comparison, it will be better for us to plot both maps next to each other as shown below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\nmap1 <- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Incidents\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex1b_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n### Visualising LISA map\n\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values.\n\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are *mean*, *median* and *pysal*. In general, classification in *mean* will be used as shown in the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa_sig <- lisa  %>%\n  filter(p_ii < 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex1b_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n## Hot Spot and Cold Spot Area Analysis (HCSA)\n\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure.\n\n## Computing local Gi\\* statistics\n\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi\\* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_idw <- Battles_2022 %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n```\n:::\n\n\nGi\\* and local Gi\\* are distance-based spatial statistics. Hence, distance methods instead of contiguity methods should be used to derive the spatial weight matrix.\n\nNow, we will compute the local Gi\\* by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    Incidents, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\nHCSA\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSimple feature collection with 74 features and 17 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 99.66532 ymax: 28.54554\nGeodetic CRS:  WGS 84\n# A tibble: 74 × 18\n   gi_star cluster    e_gi   var_gi  std_dev p_value p_sim p_folded_sim skewness\n     <dbl> <fct>     <dbl>    <dbl>    <dbl>   <dbl> <dbl>        <dbl>    <dbl>\n 1  -1.55  Low     0.0117   3.01e-5 -1.38      0.168  0.16         0.08    0.714\n 2  -1.20  Low     0.00668  4.52e-5 -0.916     0.360  0.1          0.05    1.40 \n 3  -1.46  Low     0.00847  4.61e-5 -1.15      0.252  0.06         0.03    1.26 \n 4  -1.45  Low     0.00959  5.37e-5 -1.20      0.229  0.02         0.01    1.31 \n 5  -0.465 Low     0.0126   2.36e-5 -0.348     0.728  0.8          0.4     0.290\n 6  -0.790 High    0.0155   2.84e-5 -1.14      0.256  0.26         0.13    0.674\n 7  -0.863 Low     0.0127   4.03e-5 -0.695     0.487  0.5          0.24    1.28 \n 8  -0.599 Low     0.0127   2.54e-5 -0.565     0.572  0.62         0.31    0.434\n 9  -0.188 Low     0.0121   4.50e-5  0.00294   0.998  0.92         0.46    0.778\n10   0.282 Low     0.0136   3.59e-5  0.294     0.769  0.66         0.33    0.698\n# ℹ 64 more rows\n# ℹ 9 more variables: kurtosis <dbl>, nb <nb>, wts <list>, DT <chr>,\n#   year <dbl>, event_type <chr>, Incidents <int>, Fatalities <dbl>,\n#   geometry <MULTIPOLYGON [°]>\n```\n:::\n:::\n\n\n### Visualising Gi\\*\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex1b_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n### Visualising p-value of HCSA\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex1b_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n### Visualising local HCSA\n\nFor effective comparison, you can plot both maps next to each other as shown below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\nmap1 <- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Incidents\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex1b_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n## Visualising hot spot and cold spot areas\n\nNow, we are ready to plot the significant (i.e. p-values less than 0.05) hot spot and cold spot areas by using appropriate tmap functions as shown below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA_sig <- HCSA  %>%\n  filter(p_value < 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.4)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex1b_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\nFigure above reveals that there is are 6 hot spot areas and these areas coincide with the High-high cluster identifies by using local Moran’s I method in the earlier sub-section.\n\n## \n",
    "supporting": [
      "Take-home_Ex1b_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}