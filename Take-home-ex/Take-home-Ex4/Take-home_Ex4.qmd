---
title: "Take-Home Exercise 4 - Detailed version (not for submission)"
date: February 25, 2024
author: "Imran Ibrahim"
date-modified: "last-modified"
toc: true
execute: 
  eval: true
  echo: true
  warning: false
---

# The Task

In this take-home exercise, we are required to select one of the module of our proposed Shiny application and complete the following tasks:

-   To evaluate and determine the necessary R packages needed for our Shiny application are supported in R CRAN,

-   To prepare and test the specific R codes can be run and returns the correct output as expected,

-   To determine the parameters and outputs that will be exposed on the Shiny applications,

-   To select the appropriate Shiny UI components for exposing the parameters determine above, and

-   We are required to include a section called UI design for the different components of the UIs for the proposed design.

# Getting Started

For this project on the visualisation of Armed conflicts in Myanmar, I will be preparing the codes and UI for the sections on EDA (Proportional Symbol maps), Cluster & Outlier Analysis (LISA) and Hot/Cold zone analysis.

## Loading R packages

```{r}
pacman::p_load(sf, tidyverse, tmap, dplyr,
               raster, spatstat, spdep,
               lubridate, leaflet,
               plotly, DT, viridis,
               ggplot2, sfdep)
```

## Importing the ACLED data

Country specific data from the Armed Conflict Location & Event Data Project (ACLED) can be downloaded at <https://acleddata.com/data-export-tool/>

```{r}
ACLED_MMR <- read_csv("data/MMR.csv")
```

```{r}
class(ACLED_MMR)
```

## Downloading and loading the shape files for country

Shape files were downloaded from the [Myanmmar Information Management Unit (MIMU)](https://themimu.info/about-us) website at <https://geonode.themimu.info/layers/?limit=100&offset=0>

This source was chosen over [GADM](https://gadm.org/data.html) and [GeoBoundaries](https://www.geoboundaries.org/) due to its updated administrative region information and map levels.

::: callout-important
## Important- Data Quality Issue with ACLED data

ACLED captures event data from national, sub-national and other credible media sources, and populates event locations based on the last known information.\
\
However, due to the dynamic nature of conflict and politics, country/administrative boundaries and borders can sometimes be fluid. Names of administrative areas were found to have changed; either disaggregated into new countries/administrative areas or previously active but now defunct. Further, some administrative areas were agglomerated and upgraded into higher tier administrative areas.

As part of our data cleaning and preparation process, I had to identify discrepancies in both admin1 and admin2 data levels and re-name some administrative areas to sync with the downloaded shape files from MIMU.
:::

# Data Preparation and Cleaning

## Loading Admin1(administrative region/area) shape files

```{r}
mmr_shp_mimu_1 <-  st_read(dsn = "data/geospatial3",  
                  layer = "mmr_polbnda2_adm1_250k_mimu_1")
```

```{r}
class(mmr_shp_mimu_1)
```

The Shape file for admin1 level map, is an SF object, with geometry type: Multipolygon

```{r}
st_geometry(mmr_shp_mimu_1)
```

```{r}
unique_regions_mimu1 <- unique(mmr_shp_mimu_1$ST)

unique_regions_mimu1
```

There are 18 admin1 levels or states/regions in mmr_shp_mimu_1

Lets compare with our admin1 levels in our main dataset ACLED_MMR

```{r}
unique_acled_regions1 <- unique(ACLED_MMR$admin1)

unique_acled_regions1
```

I will write a simple function to identify the discrepancies between the shape file and the region names in our main dataset.

```{r}
# Find the unique region names that are in 'unique_acled_regions1' but not in 'unique_regions_mimu1'

mismatched_admin1 <- setdiff(unique_acled_regions1, unique_regions_mimu1)

if (length(mismatched_admin1) > 0) {
  print("The following region names from 'acled_mmr' do not match any in 'mimu1':")
  print(mismatched_admin1)
} else {
  print("All unique region names in 'acled_mmr' match the unique region names in 'mimu1.'")
}
```

Lets harmonize the names in both data files. I will resave it to a new data set called ACLED_MMR_1

```{r}
ACLED_MMR_1 <- ACLED_MMR %>%
  mutate(admin1 = case_when(
    admin1 == "Bago-East" ~ "Bago (East)",
    admin1 == "Bago-West" ~ "Bago (West)",
    admin1 == "Shan-North" ~ "Shan (North)",
    admin1 == "Shan-South" ~ "Shan (South)",
    admin1 == "Shan-East" ~ "Shan (East)",
    TRUE ~ as.character(admin1)
  ))
```

Checking if our changes are successful.

```{r}
# Get unique admin 1 region names from 'ACLED_MMR_1'
unique_acled_regions1 <- unique(ACLED_MMR_1$admin1)

# Get unique region names from 'mmr_shp_mimu_1'
unique_map_regions_mimu1 <- unique(mmr_shp_mimu_1$ST)

# Find the unique region names that are in 'unique_acled_regions1' but not in 'unique_map_regions_mimu1'

mismatched_regions <- setdiff(unique_acled_regions1, unique_map_regions_mimu1)

if (length(mismatched_regions) > 0) {
  print("The following region names from 'acled_mmr_1' do not match any in 'mmr_shp_mimu_1':")
  print(mismatched_regions)
} else {
  print("All unique region names in 'acled_mmr_1' match the unique region names in 'mmmr_shp_mimu_1.'")
}
```

Lets do a sample plot to see how our country map looks like at admin1 level

```{r}
plot(mmr_shp_mimu_1)
```

## Loading Admin2 (administrative region/area) shape files

```{r}
mmr_shp_mimu_2 <-  st_read(dsn = "data/geospatial3",  
                  layer = "mmr_polbnda_adm2_250k_mimu")
```

```{r}
class(mmr_shp_mimu_2)
```

The Shape file for admin2 level map, is an SF object, with geometry type: Multipolygon

```{r}
st_geometry(mmr_shp_mimu_2)
```

```{r}
unique_regions_mimu2 <- unique(mmr_shp_mimu_2$DT)

unique_regions_mimu2
```

There are 80 admin2 levels or states/districts in mmr_shp_mimu_2

Lets compare with our admin2 levels in our main dataset ACLED_MMR

```{r}
unique_acled_regions2 <- unique(ACLED_MMR$admin2)

unique_acled_regions2
```

I will write a simple function to identify the discrepancies between the shape file and our state/district names in our main dataset.

```{r}
# Find the unique region names that are in 'unique_acled_regions2' but not in 'unique_regions_mimu2'

mismatched_admin2 <- setdiff(unique_acled_regions2, unique_regions_mimu2)

if (length(mismatched_admin2) > 0) {
  print("The following region names from 'acled_mmr' do not match any in 'mimu2':")
  print(mismatched_admin2)
} else {
  print("All unique region names in 'acled_mmr' match the unique region names in 'mimu2.'")
}
```

Lets harmonize the names in both data files. I will resave it to the previous data set called ACLED_MMR_1

```{r}
ACLED_MMR_1 <- ACLED_MMR_1 %>%
  mutate(admin2 = case_when(
    admin2 == "Yangon-East" ~ "Yangon (East)",
    admin2 == "Yangon-West" ~ "Yangon (West)",
    admin2 == "Yangon-North" ~ "Yangon (North)",
    admin2 == "Yangon-South" ~ "Yangon (South)",
    admin2 == "Mong Pawk (Wa SAD)" ~ "Tachileik",
    admin2 == "Nay Pyi Taw" ~ "Det Khi Na",
    admin2 == "Yangon" ~ "Yangon (West)",
    TRUE ~ as.character(admin2)
  ))
```

Checking if our changes are successful.

```{r}
# Get unique admin 2 district names from 'ACLED_MMR_1'
unique_acled_regions2 <- unique(ACLED_MMR_1$admin2)

# Get unique district names from 'mmr_shp_mimu_2'
unique_map_regions_mimu2 <- unique(mmr_shp_mimu_2$DT)

# Find the unique district names that are in 'unique_acled_regions2' but not in 'unique_map_regions_mimu2'

mismatched_regions2 <- setdiff(unique_acled_regions2, unique_map_regions_mimu2)

if (length(mismatched_regions2) > 0) {
  print("The following district names from 'acled_mmr_1' do not match any in 'mmr_shp_mimu_2':")
  print(mismatched_regions2)
} else {
  print("All unique district names in 'acled_mmr_1' match the unique district names in 'mmmr_shp_mimu_2.'")
}
```

```{r}
# Assuming your data frame is named 'my_data_frame'
write.csv(ACLED_MMR_1, file = "ACLED_MMR.csv", row.names = FALSE)

```

Lets do a sample plot to see how our country map looks like at admin2 (districts) level.

```{r}
plot(mmr_shp_mimu_2)
```

# Data Wrangling

For the purposes of plotting choropleth maps, I will first create attributes subsets for each admin level (1&2) grouped by year, admin region, event type and sub event type.

```{r}
Data1 <- ACLED_MMR_1 %>%
    group_by(year, admin1, event_type, sub_event_type) %>%
    summarise(Incidents = n(),
              Fatalities = sum(fatalities, na.rm = TRUE)) %>%
              
    ungroup()


Data2 <- ACLED_MMR_1 %>%
    group_by(year, admin2, event_type, sub_event_type) %>%
    summarise(Incidents = n(),
              Fatalities = sum(fatalities, na.rm = TRUE)) %>%
              
    ungroup()


```

Checking the total sum of incidents and fatalities

```{r}

total_incidents1 <- sum(Data1$Incidents)
total_incidents2 <- sum(Data2$Incidents)
total_fatalities1 <- sum(Data1$Fatalities)
total_fatalities2 <- sum(Data2$Fatalities)

```

```{r}
total_incidents1
total_incidents2
total_fatalities1
total_fatalities2
```

Next, I will do a spatial join between my shape files and attribute files

```{r}
ACLED_MMR_admin1 <- left_join(mmr_shp_mimu_1, Data1,
                            by = c("ST" = "admin1"))

ACLED_MMR_admin2 <- left_join(mmr_shp_mimu_2, Data2,
                            by = c("DT" = "admin2"))
```

```{r}
class(ACLED_MMR_admin1)
```

```{r}
class(ACLED_MMR_admin2)
```

Checking that total sum of incidents and fatalities in our SF files are correct as per our original datasets

```{r}
total_incidents3 <- sum(ACLED_MMR_admin1$Incidents)
total_incidents4 <- sum(ACLED_MMR_admin2$Incidents)
total_fatalities3 <- sum(ACLED_MMR_admin1$Fatalities)
total_fatalities4 <- sum(ACLED_MMR_admin2$Fatalities)

total_incidents3
total_incidents4
total_fatalities3
total_fatalities4
```

# Choropleth Maps

## Choropleth Map of Incidents & Fatalities by Admin1 (Region/State)

In the Shiny App, the below choropleth maps can be plotted, with users being able to choose the following:-

-   Variable: Count of Incidents or Fatalities

-   specific year or year range

-   event type and sub event type

-   data classification type, and

-   number of clusters (n)

::: panel-tabset
## Fatalities in Battles in 2022, by Quantiles

```{r}
ACLED_MMR_admin1 %>%
  filter(year == 2022, event_type == "Battles") %>%
  tm_shape() +
  tm_fill("Fatalities",
          n = 5,
          style = "quantile",
          palette = "Reds") +
  tm_borders(alpha = 0.5)
```

## Fatalities in Violence against civilians in 2022, by quantiles

```{r}
ACLED_MMR_admin1 %>%
  filter(year == 2022, event_type == "Violence against civilians") %>%
  tm_shape() +
  tm_fill("Fatalities",
          n = 5,
          style = "quantile",
          palette = "Reds") +
  tm_borders(alpha = 0.5)
```

## Incidents of Riots in 2021, by jenks

```{r}
ACLED_MMR_admin1 %>%
  filter(year == 2021, event_type == "Riots") %>%
  tm_shape() +
  tm_fill("Incidents",
          n = 5,
          style = "jenks",
          palette = "Reds") +
  tm_borders(alpha = 0.5)
```

## Fatalities in Battles, by sub event = Armed clash, in 2023 (Quantile)

```{r}
ACLED_MMR_admin1 %>%
  filter(year == 2023, event_type == "Battles", sub_event_type == "Armed clash" ) %>%
  tm_shape() +
  tm_fill("Fatalities",
          n = 5,
          style = "quantile",
          palette = "Reds") +
  tm_borders(alpha = 0.5)
```

## Fatalities in Explosions, by sub event = Shelling/Artillery, in 2023 (Quantile)

```{r}
ACLED_MMR_admin1 %>%
  filter(year == 2023, event_type == "Explosions/Remote violence", sub_event_type == "Shelling/artillery/missile attack" ) %>%
  tm_shape() +
  tm_fill("Fatalities",
          n = 5,
          style = "quantile",
          palette = "Reds") +
  tm_borders(alpha = 0.5)
```
:::

## Choropleth map of Incidents & Fatalities by Admin2 level (by District)

Similarly, in the Shiny App, the below choropleth maps can be plotted, with users being able to choose the following:-

-   Variable: Count of Incidents or Fatalities

-   specific year or year range

-   event type and sub event type

-   data classification type, and

-   number of clusters (n)

::: panel-tabset
## Fatalities in Battles in 2023, by districts (Quantile)

```{r}
ACLED_MMR_admin2 %>%
  filter(year == 2023, event_type == "Battles") %>%
  tm_shape() +
  tm_fill("Fatalities",
          n = 5,
          style = "quantile",
          palette = "Reds") +
  tm_borders(alpha = 0.5)
```

## Incidents in Violence against civilians by sub event = Attack in 2021 (Quantile)

```{r}
ACLED_MMR_admin2 %>%
  filter(year == 2021, event_type == "Violence against civilians", sub_event_type == "Attack" ) %>%
  tm_shape() +
  tm_fill("Incidents",
          n = 5,
          style = "quantile",
          palette = "Reds") +
  tm_borders(alpha = 0.5)
```

## Fatalities in Explosions, sub event= Air/drone strike in 2023

```{r}
ACLED_MMR_admin2 %>%
  filter(year == 2023, event_type == "Explosions/Remote violence", sub_event_type == "Air/drone strike" ) %>%
  tm_shape() +
  tm_fill("Incidents",
          n = 5,
          style = "quantile",
          palette = "Reds") +
  tm_borders(alpha = 0.5)
```
:::

## Incidents and Fatalities by individual regions using `tm_facet()`

::: panel-tabset
## Fatalities in Battles, sub event = Armed Clash in 2023 by Region

```{r}
ACLED_MMR_admin1 %>%
  filter(year == 2023, event_type == "Battles", sub_event_type == "Armed clash" ) %>%
tm_shape( ) +
  tm_fill("Fatalities",
          style = "quantile",
          palette = "Reds",
          thres.poly = 0) + 
  tm_facets(by="ST", 
            free.coords=TRUE, 
            drop.shapes=TRUE) +
  tm_layout(legend.show = FALSE,
            title.position = c("center", "center"), 
            title.size = 20) +
  tm_borders(alpha = 0.5)
```

## Incidents of Violence against civilians in 2022 by Region

```{r}
ACLED_MMR_admin1 %>%
  filter(year == 2022, event_type == "Violence against civilians") %>%
tm_shape( ) +
  tm_fill("Incidents",
          style = "quantile",
          palette = "Reds",
          thres.poly = 0) + 
  tm_facets(by="ST", 
            free.coords=TRUE, 
            drop.shapes=TRUE) +
  tm_layout(legend.show = FALSE,
            title.position = c("center", "center"), 
            title.size = 20) +
  tm_borders(alpha = 0.5)
```
:::

The above plots using `tm_facet()` may not necessarily add value to users, so I will KIV for the app.

# Proportional Symbol Maps

Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people.

First I will convert the ACLED_MMR_1 data set to become an sf object

```{r}
# Convert conflict data to an sf object
conflict_sf <- st_as_sf(ACLED_MMR_1, coords = c("longitude", "latitude"), crs = 4326)

```

```{r}
class(conflict_sf)
```

```{r}
conflict_sf
```

Next, I create subsets for each event type, each subset will inherit the SF object characteristic.

```{r}
Battles <- filter(conflict_sf, event_type == "Battles")
Violence_CV <- filter(conflict_sf, event_type == "Violence against civilians")
Protests <- filter(conflict_sf, event_type == "Protests")
Riots <- filter(conflict_sf, event_type == "Riots")
Explosions <- filter(conflict_sf, event_type == "Explosions/Remote violence")
Strategic_dev <- filter(conflict_sf, event_type == "Strategic developments")
```

```{r}
class(Battles)
```

## Visualising of Fatalities by Event Type

In the shiny App , we can enable users to filter by

-   specific year,

-   year range, and

-   event_type

-   range of number of fatalities

By using subsets of event types which have been converted to sf objects.

I will use the Geometry points from our data sets to plot the points of events in the maps using the leaflet package.

In this case, i will use admin 1 level regions, to achieve a better aesthetics for users. ie dividing the country map into more districts would likely look too busy, and not value add to users. Further, additional information on the specific event type, region, year, no of fatalities and actors involved can be communicated by means of the tooltip.

::: panel-tabset
## Battles from 2010 to present

```{r}
scaleFactor <- 2  

leaflet(Battles) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(data = mmr_shp_mimu_1, color = "#444444", weight = 1, fillOpacity = 0.5) %>% # Adding borders
  
  addCircleMarkers(popup = ~paste("Event: Battles<br>State/Region:", admin1, 
                                  "<br>Actor1:", actor1, "<br>Actor2:", actor2,
                                  "<br>Year:", year, "<br>Fatalities:", fatalities),
                   radius = ~sqrt(fatalities) * scaleFactor,
                   fillColor = "red", fillOpacity = 0.4, color = "#FFFFFF", weight = 1) %>% 
  setView(lng = 96.1603, lat = 19.745, zoom = 6)
```

## Violence against civilians from 2010 to present

```{r}
scaleFactor <- 2  

leaflet(Violence_CV) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(data = mmr_shp_mimu_1, color = "#444444", weight = 1, fillOpacity = 0.5) %>% # Adding borders
  
  addCircleMarkers(popup = ~paste("Event: Violence on Civillians<br>State/Region:", admin1, 
                                  "<br>Actor1:", actor1, "<br>Actor2:", actor2,
                                  "<br>Year:", year, "<br>Fatalities:", fatalities),
                   radius = ~sqrt(fatalities) * scaleFactor,
                   fillColor = "red", fillOpacity = 0.4, color = "#FFFFFF", weight = 1) %>% 
  setView(lng = 96.1603, lat = 19.745, zoom = 6)
```

## Protests from 2010 to present

```{r}
scaleFactor <- 2  

leaflet(Protests) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(data = mmr_shp_mimu_1, color = "#444444", weight = 1, fillOpacity = 0.5) %>% # Adding borders
  
  addCircleMarkers(popup = ~paste("Event: Protests<br>State/Region:", admin1, 
                                  "<br>Actor1:", actor1, "<br>Actor2:", actor2,
                                  "<br>Year:", year, "<br>Fatalities:", fatalities),
                   radius = ~sqrt(fatalities) * scaleFactor,
fillColor = "red", fillOpacity = 0.4, color = "#FFFFFF", weight = 1) %>% 
  setView(lng = 96.1603, lat = 19.745, zoom = 6)
```

## Riots from 2010 to present

```{r}
scaleFactor <- 2  

leaflet(Riots) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(data = mmr_shp_mimu_1, color = "#444444", weight = 1, fillOpacity = 0.5) %>% # Adding borders
  
  addCircleMarkers(popup = ~paste("Event: Riots<br>State/Region:", admin1, 
                                  "<br>Actor1:", actor1, "<br>Actor2:", actor2,
                                  "<br>Year:", year, "<br>Fatalities:", fatalities),
                   radius = ~sqrt(fatalities) * scaleFactor,
                   fillColor = "red", fillOpacity = 0.4, color = "#FFFFFF", weight = 1) %>% 
  setView(lng = 96.1603, lat = 19.745, zoom = 6)
```

## Explosions/Remote Devices from 2010 to present

```{r}
scaleFactor <- 2  

leaflet(Explosions) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(data = mmr_shp_mimu_1, color = "#444444", weight = 1, fillOpacity = 0.5) %>% # Adding borders
  
  addCircleMarkers(popup = ~paste("Event: Explosions<br>State/Region:", admin1, 
                                  "<br>Actor1:", actor1, "<br>Actor2:", actor2,
                                  "<br>Year:", year, "<br>Fatalities:", fatalities),
                   radius = ~sqrt(fatalities) * scaleFactor,
fillColor = "red", fillOpacity = 0.4, color = "#FFFFFF", weight = 1) %>% 
  
  setView(lng = 96.1603, lat = 19.745, zoom = 6)
```
:::

# Data Preparation for Spatial Analysis

First I will create subsets of our Events happening in admin region 1 & 2, summarized with the number(count) of incidents and fatalities.

```{r}
Events1 <- ACLED_MMR_1 %>%
    group_by(year, admin1, event_type) %>%
    summarise(Incidents = n(),
              Fatalities = sum(fatalities, na.rm = TRUE)) %>%
              
    ungroup()


Events2 <- ACLED_MMR_1 %>%
    group_by(year, admin2, event_type) %>%
    summarise(Incidents = n(),
              Fatalities = sum(fatalities, na.rm = TRUE)) %>%
              
    ungroup()

```

Next, we will perform a relational join to update our admin 1 and admin 2 level shape files with attributes fields of the above event related data.

```{r}
Events_admin1 <- left_join(mmr_shp_mimu_1, Events1,
                            by = c("ST" = "admin1"))

Events_admin2 <- left_join(mmr_shp_mimu_2, Events2,
                            by = c("DT" = "admin2"))
```

The class of the file is SF objects file

```{r}
class(Events_admin1)
```

```{r}
st_geometry(Events_admin2)
```

Next, I will create a subset of the event type and year.

For example, for the puposes of this exercise, the codes below will be used to analyse for Event type = Battles, in the year 2023\
\
I will name the object as `Battles_2023`, eventually this object file will be named generically (eg: Event_Year), so that users can select for different event types and different years in the Shiny app.

### Filtering the Event and Year (Event type = Battles, in 2023)

```{r}
Battles_2023 <- Events_admin2 %>%
  filter(year == 2023, event_type == "Battles")
```

### Computing Contiguity Spatial Weights

Before we can compute any spatial statistics, we need to construct spatial weights of the study area.

The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. admin2) in the study area (Myanmar).

In the code below, [`poly2nb()`](https://r-spatial.github.io/spdep/reference/poly2nb.html) of **spdep** package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries.

By default this function will return a list of first order neighbours using the Queen criteria.

However, we can pass a “queen” argument that takes TRUE or FALSE as options.

```{r}
wm_q <- poly2nb(Battles_2023, 
                queen=TRUE)
summary(wm_q)
```

The summary report above shows that there are 74 area units for this subset (Battles occurring in 2023).\
\
There are 2 most connected area units with 10 neighbours, and there are 3 area units with only 1 neighbours.

### Row-standardised weights matrix

Next, we assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring admin2 (district) and then summing the weighted income values.

This has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons and thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.

For this example, I will stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.

```{r}
rswm_q <- nb2listw(wm_q, 
                   style="W", 
                   zero.policy = TRUE)
rswm_q
```

::: callout-note
## Note - Studying Spatial Autocorrelation at the Local Level.

While **GLOBAL** Moran’s I score and the Geary’s C ratio can tell us whether specific event types (Battles, Explosions, Protests, Riots, Violence against civilians) tends to cluster or not on the map, it does not provide any information on the **distribution of spatial dependence** of Events types, and is unable to identify the location of **hotspots and clusters.**

For that, we require the use of more localized methods - Anselin’s Moran Scatterplot and the Local Indicator of Spatial Autocorrelation (LISA) method.
:::

# Cluster and Outlier Analysis

Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. For example, in this analysis, we are studying if there are areas that have higher or lower incidents of a specific Event type (Battles) than is to be expected by chance alone, ie the values occurring are above or below those of a random distribution in space.

## Computing local Moran’s I

To compute local Moran’s I, the [*localmoran()*](https://r-spatial.github.io/spdep/reference/localmoran.html) function of **spdep** will be used. It computes *Ii* values, given a set of *zi* values and a listw object providing neighbour weighting information for the polygon associated with the zi values.

```{r}
fips <- order(Battles_2023$DT)
localMI <- localmoran(Battles_2023$Incidents, rswm_q)
head(localMI)
```

*localmoran()* function returns a matrix of values whose columns are:

-   Ii: the local Moran’s I statistics

-   E.Ii: the expectation of local moran statistic under the randomisation hypothesis

-   Var.Ii: the variance of local moran statistic under the randomisation hypothesis

-   Z.Ii:the standard deviate of local moran statistic

-   Pr(): the p-value of local moran statistic

The code below lists the content of the local Moran matrix derived by using [*printCoefmat()*](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/printCoefmat).

```{r}
printCoefmat(data.frame(
  localMI[fips,], 
  row.names=Battles_2023$DT[fips]),
  check.names=FALSE)
```

## Mapping the local Moran’s I

Before mapping the local Moran’s I map, we will need to append the local Moran’s I dataframe (i.e. localMI) onto the Battles_2023's SF DataFrame.

```{r}
Battles_2023.localMI <- cbind(Battles_2023,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

```{r}
Battles_2023.localMI
```

## Mapping local Moran’s I values

Using choropleth mapping functions of **tmap** package, we can plot the local Moran’s I values by using the code below.

```{r}
tm_shape(Battles_2023.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

## Mapping local Moran’s I p-values

The choropleth shows there is evidence for both positive and negative Ii values. However, we will also need to consider the p-values for each of these values.

The code below produces a choropleth map of Moran’s I p-values by using functions of **tmap** package.

```{r}
tm_shape(Battles_2023.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

## Mapping both local Moran’s I values and p-values

For the Shiny App, it will be better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.

The code below will be used to create such visualisation.

```{r}
localMI.map <- tm_shape(Battles_2023.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(Battles_2023.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

# Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.

## Plotting Moran scatterplot

The Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.

The code below plots the Moran scatterplot of Battles in 2023 by using [*moran.plot()*](https://r-spatial.github.io/spdep/reference/moran.plot.html) of **spdep**.

```{r}
nci <- moran.plot(Battles_2023$Incidents, rswm_q,
                  labels=as.character(Battles_2023$DT), 
                  xlab="Battles_2023", 
                  ylab="Spatially Lagged Events,Year")
```

The plot is split in 4 quadrants. The top right corner belongs to areas that have high incidents of events and are surrounded by other areas that have higher than the average level/number of battles This is the high-high locations.

::: callout-note
## Note

The Moran scatterplot is divided into four areas, with each quadrant corresponding with one of four categories: (1) High-High (HH) in the top-right quadrant; (2) High-Low (HL) in the bottom right quadrant; (3) Low-High (LH) in the top-left quadrant; (4) Low- Low (LL) in the bottom left quadrant.
:::

## Plotting Moran scatterplot with standardised variable

First I will use [*scale()*](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/scale) to centre and scale the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centred) variable by their standard deviations.

```{r}
Battles_2023$Z.Incidents <- scale(Battles_2023$Incidents) %>% 
  as.vector 
```

The [*as.vector()*](https://www.rdocumentation.org/packages/pbdDMAT/versions/0.5-1/topics/as.vector) added to the end is to make sure that the data type we get out of this is a vector, that maps neatly into our dataframe.

Next, we plot the Moran scatterplot again by using the code below.

```{r}
nci2 <- moran.plot(Battles_2023$Z.Incidents, rswm_q,
                   labels=as.character(Battles_2023$DT),
                   xlab="z-Battles in 2023", 
                   ylab="Spatially Lag z-Battles in 2023")
```

### Moran Scatterplots from 2020-2023 , Battles

**2020**

![](images/clipboard-2694083671.png)

**2021**

![](images/clipboard-1000411604.png)

**2022**

![](images/clipboard-466306435.png)

**2023**

![](images/clipboard-392064135.png)

Both types of scatter plots can be implemented for the Shiny app, with users being able to select between standardised or non-standardised variables.

::: callout-note
## Note

High-High (HH): indicates high spatial correlation where incidents of Battles are clustered closely together. 2) High-Low (HL): where areas of high frequency of incidents of Battles occurred are located next to areas where there is low frequency of incidents of Battles occurred. 3) Low-High (LH): these are areas of low frequency of incidents where Battles occurred that are located next to areas where high frequency of Battles. 4) Low-Low (LL): these are clusters of low frequency of incidents of Battles occurred.
:::

## Preparing LISA map classes

The Moran Scatterplot has one drawback - it does not indicate whether these regions are significant or not. We can address this limitation by using the LISA method. LISA will not only allow us to identify the hotspot locations, but also the statistical significance of the hot spots in the map.

According to Anselin (1995), LISA can be used to locate “hot spots” or local spatial clusters where the occurrence of Event types is statistically significant.

In addition to the four categories described in the Moran Scatterplot, the LISA analysis includes an additional category: (5) Insignificant: where there are no spatial autocorrelation or clusters where event types have occurred.

The code below shows the steps to prepare a LISA cluster map.

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
```

Next, we derive the spatially lagged variable of interest (i.e. Incidents) and centers the spatially lagged variable around its mean.

```{r}
Battles_2023$lag_Incidents <- lag.listw(rswm_q, Battles_2023$Incidents)
DV <- Battles_2023$lag_Incidents - mean(Battles_2023$lag_Incidents)     
```

This is followed by centering the local Moran’s around the mean.

```{r}
LM_I <- localMI[,1] - mean(localMI[,1])    
```

Next, we will set a statistical significance level for the local Moran.

```{r}
signif <- 0.05       
```

These four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.

```{r}
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4      
```

Lastly, we place non-significant Moran in the category 0.

```{r}
quadrant[localMI[,5]>signif] <- 0
```

We can also combine all the steps above into one single code chunk as shown below:

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
Battles_2023$lag_Incidents <- lag.listw(rswm_q, Battles_2023$Incidents)
DV <- Battles_2023$lag_Incidents - mean(Battles_2023$lag_Incidents)     
LM_I <- localMI[,1]   
signif <- 0.05       
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4    
quadrant[localMI[,5]>signif] <- 0
```

## Plotting LISA Map

Now, we can build the LISA map by using the code below.

```{r}
Battles_2023.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(Battles_2023.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

We can also plot the choropleth map of incidents of Battles in 2023 together with the LISA map

```{r}
Incidents <- qtm(Battles_2023, "Incidents")

Battles_2023.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(Battles_2023.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(Incidents, LISAmap,
             asp=1, ncol=2)
```

We can also include the local Moran’s I map and p-value map as shown below for easy comparison.

```{r}
tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

To see the full effect of the LISA maps by event type, we will need to view this over time to see how it has changed over time.\

#### LISA Maps for Battles in 2020-2023

2020

![](images/clipboard-170596739.png)

**2021**

![](images/clipboard-1503795972.png)

**2022**

![](images/clipboard-1875261868.png)

**2023**

![](images/clipboard-3383112591.png)

For our Shiny App, I will combine these 4 plots into a single page for users.

# Hot Spot and Cold Spot Area Analysis

Beside detecting for clusters and outliers, Localised spatial statistics can be also used to detect hot spot and/or cold spot areas.

The term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).

## Getis and Ord’s G-Statistics

An alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995).

It looks at neighbours within a defined proximity to identify where either high or low values cluster spatially.

Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.

The analysis consists of three steps:

-   Deriving spatial weight matrix

-   Computing Gi statistics

-   Mapping Gi statistics

### Deriving distance-based weight matrix

First, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.

There are two type of distance-based proximity matrix, they are:

-   fixed distance weight matrix; and

-   adaptive distance weight matrix.

### Deriving the centroid

We will need points to associate with each polygon before we can make our connectivity graph.

We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length.

Our input vector will be the geometry column of Battles_2023 dataset. Our function will be *st_centroid()*. We will be using map_dbl variation of map from the purrr package.

To get our longitude values we map the *st_centroid()* function over the geometry column of our Battles_2023 dataset and access the longitude value through double bracket notation \[\[\]\] and 1. This allows us to get only the longitude, which is the first value in each centroid.

```{r}
longitude <- map_dbl(Battles_2023$geometry, ~st_centroid(.x)[[1]])
```

```{r}
class(longitude)
```

```{r}
longitude
```

We do the same for latitude with one key difference. We access the second value per each centroid with \[\[2\]\].

```{r}
latitude <- map_dbl(Battles_2023$geometry, ~st_centroid(.x)[[2]])
```

```{r}
class(latitude)
```

```{r}
latitude
```

Now that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.

```{r}
coords <- cbind(longitude, latitude)
```

```{r}
class(coords)
```

```{r}
coords
```

### Determine the cut-off distance

Firstly, we need to determine the upper limit for distance band by using the steps below:

-   Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using [*knearneigh()*](https://r-spatial.github.io/spdep/reference/knearneigh.html) of **spdep**.

-   Convert the knn object returned by *knearneigh()* into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using [*knn2nb()*](https://r-spatial.github.io/spdep/reference/knn2nb.html).

-   Return the length of neighbour relationship edges by using [*nbdists()*](https://r-spatial.github.io/spdep/reference/nbdists.html) of **spdep**. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.

-   Remove the list structure of the returned object by using [**unlist()**](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unlist).

```{r}
k1 <- knn2nb(knearneigh(coords))

```

```{r}
class(k1)
```

```{r}
k1
```

```{r}
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))

```

```{r}
class(k1dists)
```

```{r}
k1dists
```

```{r}
summary(k1dists)
```

The summary report shows that the largest first nearest neighbour distance is 196.85 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

```{r}
wm_d197 <- dnearneigh(coords, 0, 197, longlat = TRUE)
wm_d197
```

Next, *nb2listw()* is used to convert the nb object into spatial weights object.

```{r}
wm197_lw <- nb2listw(wm_d197, style = 'B')
summary(wm197_lw)
```

```{r}
class(wm197_lw)
```

The output spatial weights object is called `wm197_lw`.

### Computing adaptive distance weight matrix

One of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours.

Having many neighbours smoothes the neighbour relationship across more neighbours.

It is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code below.

```{r}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

```{r}
class(knn)
```

Next, *nb2listw()* is used to convert the nb object into spatial weights object.

```{r}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

```{r}
class(knn_lw)
```

## Computing Gi statistics

### Gi statistics using fixed distance

```{r}
fips <- order(Battles_2023$DT)
fips
```

```{r}
class(fips)
```

```{r}
gi.fixed <- localG(Battles_2023$Incidents, wm197_lw)
gi.fixed
```

```{r}
class(gi.fixed)
```

Next, we will join the Gi values to their corresponding sf data frame by using the code chunk below.

```{r}
Battles_2023.gi <- cbind(Battles_2023, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

```{r}
class(Battles_2023.gi)
```

```{r}
Battles_2023.gi
```

The code above performs three tasks. First, it converts the output vector (i.e. *gi.fixed*) into r matrix object by using *as.matrix()*. Next, *cbind()* is used to join Battles_2023 and *gi.fixed* matrix to produce a new SpatialPolygonDataFrame called *Battles_2023.gi*. Lastly, the field name of the gi values is renamed to *gstat_fixed* by using *rename()*.

## Mapping Gi values with fixed distance weights

The code below shows the functions used to map the Gi values derived using fixed distance weight matrix.

```{r}
Events_Years <- qtm(Battles_2023, "Incidents")

Gimap <-tm_shape(Battles_2023.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "Fixed Distance\nlocal Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(Events_Years, Gimap, asp=1, ncol=2)
```

### Gi statistics using adaptive distance

The code below is used to compute the Gi values for Incidents of Battles in 2023 by using an adaptive distance weight matrix (i.e *knb_lw*).

```{r}
fips <- order(Battles_2023$DT)
gi.adaptive <- localG(Battles_2023$Incidents, knn_lw)

```

```{r}
gi.adaptive
```

```{r}
class(gi.adaptive)
```

```{r}
Battles_2023.gi <- cbind(Battles_2023, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

```{r}
datatable(Battles_2023.gi)
```

## Mapping Gi values with adaptive distance weights

Now we visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of **tmap** package will be used to map the Gi values.

The code below shows the functions used to map the Gi values derived using fixed distance weight matrix.

```{r}
Events_Years<- qtm(Battles_2023, "Incidents")

Gimap <- tm_shape(Battles_2023.gi) + 
  tm_fill(col = "gstat_adaptive", 
          style = "pretty", 
          palette="-RdBu", 
          title = "Adaptive Distance\nlocal Gi") + 
  tm_borders(alpha = 0.5)

tmap_arrange(Events_Years, 
             Gimap, 
             asp=1, 
             ncol=2)
```

### Comparing Fixed distance and Adaptive Distance

![](images/clipboard-2611857874.png)

![](images/clipboard-1647384731.png)

There is a few subtle differences between the Fixed and Adaptive distances.

Lastly, to see the full effect of the HOT & Cold spots by event type, we can also view the maps over time to see how hot and cold spots have changed.\

#### Hot & Cold Spots for Battles in 2020-2023 (adaptive distance)

**2020**

![**2021**](images/clipboard-3169172241.png)

![**2022**](images/clipboard-3172227594.png)

![](images/clipboard-264827815.png)

**2023**

![](images/clipboard-2567179488.png)

# References

Main reference: Kam, T.S. (2024). [Local Measures of Spatial Autocorrelation](https://r4gdsa.netlify.app/chap10#overview)
